{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from utils_model import *\n",
    "from tensorflow.keras.layers import Conv2D, Add, Multiply\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Softmax, Input\n",
    "from tensorflow.keras import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PAM(inp_feature, layer_name, kernel_initializer='glorot_uniform', acti='relu'):\n",
    "    '''\n",
    "    Position attention module\n",
    "    by default input shape => [w,h,c],[240, 240, 128] hence c/8 = 16\n",
    "    :param layer_name: List of layer names\n",
    "    [1st conv block, 2nd conv block, softmax output, 3rd conv block, position coefficient, Add output]\n",
    "    :param inp_feature: feature maps of res block after up sampling [w,h,c]\n",
    "    :return: PAM features [w/4,h/4,c]\n",
    "    '''\n",
    "    # dimensions\n",
    "    b,w,h,c = inp_feature.shape\n",
    "    # scale down ratio\n",
    "    c_8 = c//8\n",
    "    #\n",
    "    assert len(layer_name)>=5, 'Layer list length should be 5!'\n",
    "    # Branch01 Dimension: [w,h,c/8] => [(wxh),c/8]\n",
    "    query = conv_2d(inp_feature, filters=c_8, layer_name=layer_name[0], batch_norm=False, kernel_size=(1, 1), acti=acti,\n",
    "            kernel_initializer=kernel_initializer, dropout_rate=None)\n",
    "    query = tf.reshape(query,[-1,(w*h),c_8 ])\n",
    "    # Branch02 Dimension: [w,h,c/8] => [c/8,(wxh)]\n",
    "    key = conv_2d(inp_feature, filters=c_8, layer_name=layer_name[1], batch_norm=False, kernel_size=(1, 1), acti=acti,\n",
    "        kernel_initializer=kernel_initializer, dropout_rate=None)\n",
    "    key = tf.reshape(key, [-1,(w*h),c_8 ])\n",
    "    key = tf.einsum('bij->bji', key) # transpose/permutation\n",
    "    # matmul pipeline 01 & 02\n",
    "    matmul_0102 = tf.einsum('bij,bjk->bik', query, key) # [(wxh),(wxh)]\n",
    "    #attention coefficient\n",
    "    alpha_p = Softmax(name=layer_name[2])(matmul_0102) # [(wxh),(wxh)]\n",
    "    # Branch03\n",
    "    value = conv_2d(inp_feature, filters=c, layer_name=layer_name[3], batch_norm=False, kernel_size=(1, 1), acti=acti,\n",
    "        kernel_initializer=kernel_initializer, dropout_rate=None)\n",
    "    value = tf.reshape(value,[-1,(w*h),c]) # [(wxh),c]\n",
    "    matmul_all = tf.einsum('bij,bjk->bik',alpha_p,value) # [(wxh),c]\n",
    "    # Output\n",
    "    output = tf.reshape(matmul_all, [-1,w,h,c]) # [w,h,c]\n",
    "    # learnable coefficient to control the importance of CAM\n",
    "    lambda_p = Conv2D(filters=1,kernel_size=1, padding='same',activation='sigmoid', name=layer_name[4])(inp_feature)\n",
    "    output = Multiply()([output, lambda_p])\n",
    "    output_add = Add(name = layer_name[-1])([output, inp_feature])\n",
    "    return output_add\n",
    "\n",
    "def CAM(inp_feature, layer_name):\n",
    "    '''\n",
    "    Channel attention module\n",
    "    by default input shape => [w,h,c],[240, 240, 128] hence c/8 = 16\n",
    "    :param inp_feature: feature maps of res block after up sampling [w,h,c]k\n",
    "    :param layer_name: List of layer names\n",
    "        [softmax output, channel attention coefficients, Add output]\n",
    "    :return: CAM features [w/4,h/4,c]\n",
    "    '''\n",
    "    # dimensions\n",
    "    b,w,h,c = inp_feature.shape\n",
    "    # learnable coefficient to control the importance of CAM\n",
    "    assert len(layer_name)>=2, 'Layer list length should be 2!'\n",
    "    # Branch01 Dimension: [w,h,c] => [(wxh),c]\n",
    "    query = tf.reshape(inp_feature, [-1,(w*h),c])\n",
    "    # Branch02 Dimension: [w,h,c] => [c,(wxh)]\n",
    "    key = tf.reshape(inp_feature, [-1,(w*h),c]) # [(wxh),c]\n",
    "    key = tf.einsum('ijk->ikj', key) # Permute:[c,(wxh)]\n",
    "    # matmul pipeline 01 & 02\n",
    "    matmul_0201 = tf.einsum('ijk,ikl->ijl', key, query) # [c,c]\n",
    "    #attention coefficient\n",
    "    alpha_c = Softmax(name=layer_name[0])(matmul_0201) # [c,c]\n",
    "    # Branch03 Dimension: [w,h,c] => [c,(wxh)]\n",
    "    value = tf.reshape(inp_feature,[-1,(w*h),c]) # [(wxh),c]\n",
    "    matmul_all = tf.einsum('ijk,ikl->ijl', value, alpha_c) # [(wxh),c]\n",
    "    # output\n",
    "    output = tf.reshape(matmul_all,[-1,w,h,c])# [w,h,c]\n",
    "    #\n",
    "    lambda_c = tf.keras.backend.variable(tf.zeros([1]), dtype='float32')\n",
    "    output = Multiply()([output, lambda_c])\n",
    "    output_add = Add(name=layer_name[-1])([output, inp_feature])\n",
    "    return output_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "class att_var(layers.Layer):\n",
    "    '''\n",
    "    Attention variable\n",
    "    '''\n",
    "    def __init__(self, initial_val):\n",
    "        super(att_var, self).__init__()\n",
    "        self.initial_val = initial_val\n",
    "    def __call__(self):\n",
    "        lambda_ = tf.Variable(initial_value=self.initial_val, trainable=True)\n",
    "        return lambda_\n",
    "\n",
    "lambda_c = att_var(tf.zeros([1]))\n",
    "tst = lambda_c()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "layer_name_p01 = ['pam01_conv01', 'pam01_conv02', 'pam01_softmax', 'pam01_conv03',\n",
    "                  'pam01_alpha','pam01_add']\n",
    "layer_name_c01 = ['cam01_softmax', 'cam01_alpha','cam01_add']\n",
    "layer_name_p02 = ['pam02_conv01', 'pam02_conv02', 'pam02_softmax', 'pam02_conv03',\n",
    "                  'pam02_alpha', 'pam02_add']\n",
    "layer_name_c02 = ['cam02_softmax', 'cam02_alpha','cam02_add']\n",
    "layer_name_template = [layer_name_p01, layer_name_c01, layer_name_p02, layer_name_c02]\n",
    "\n",
    "layer_name_ga = []\n",
    "for b in range(1,4):\n",
    "    layer_block = []\n",
    "    for layer in layer_name_template:\n",
    "        layer_internal = [i+'block0{}'.format(b) for i in layer]\n",
    "        layer_block.append(layer_internal)\n",
    "    layer_name_ga.append(layer_block)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "hn = 'he_normal' #kernel initializer\n",
    "lambda_ = tf.keras.backend.variable(tf.zeros([1]), dtype='float32')\n",
    "input_layer = Input(shape=(200,200,128))\n",
    "model = Model(input_layer, CAM(input_layer, layer_name_ga[0][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_13\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_9 (InputLayer)            [(None, 200, 200, 12 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_25 (TensorF [(None, 40000, 128)] 0           input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Einsum_18 (TensorFl [(None, 128, 40000)] 0           tf_op_layer_Reshape_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_24 (TensorF [(None, 40000, 128)] 0           input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Einsum_19 (TensorFl [(None, 128, 128)]   0           tf_op_layer_Einsum_18[0][0]      \n",
      "                                                                 tf_op_layer_Reshape_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_26 (TensorF [(None, 40000, 128)] 0           input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "cam01_softmaxblock01 (Softmax)  (None, 128, 128)     0           tf_op_layer_Einsum_19[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Einsum_20 (TensorFl [(None, 40000, 128)] 0           tf_op_layer_Reshape_26[0][0]     \n",
      "                                                                 cam01_softmaxblock01[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_27 (TensorF [(None, 200, 200, 12 0           tf_op_layer_Einsum_20[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul_4 (TensorFlowOp [(None, 200, 200, 12 0           tf_op_layer_Reshape_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "cam01_addblock01 (Add)          (None, 200, 200, 128 0           tf_op_layer_Mul_4[0][0]          \n",
      "                                                                 input_9[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 0\n",
      "Trainable params: 0\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Conv3D"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv3D, UpSampling3D, MaxPool3D, GaussianNoise\n",
    "\n",
    "hn = 'he_normal' #kernel initializer\n",
    "\n",
    "def conv_block_3D(x, filters, norm_fn='gn', kernel_size=3,\n",
    "               kernel_initializer=hn, acti_fn='prelu', dropout_rate=None):\n",
    "    '''\n",
    "    Dual convolution block with [full pre-activation], Norm -> Acti -> Conv\n",
    "    :param x: Input features\n",
    "    :param filters: A list that contains the number of filters for 1st and 2nd convolutional layer\n",
    "    :param norm_fn: Tensorflow function for normalization, 'bn' for Batch Norm, 'gn' for Group Norm\n",
    "    :param kernel_size: Kernel size for both convolutional layer with 3x3 as default\n",
    "    :param kernel_initializer: Initializer for kernel weights with 'glorot uniform' as default\n",
    "    :param acti_fn: Tensorflow function for activation, 'relu' for ReLU, 'prelu' for PReLU\n",
    "    :param dropout_rate: Specify dropouts for layers\n",
    "    :return: Feature maps of same size as input with number of filters equivalent to the last layer\n",
    "    '''\n",
    "    assert type(filters)==list, \"Please input filters of type list.\"\n",
    "    assert acti_fn!= None, 'There should be an activation functino specified'\n",
    "    #1st convolutional block\n",
    "    if norm_fn=='bn':\n",
    "        x = BatchNormalization()(x)\n",
    "    elif norm_fn=='gn':\n",
    "        x = GroupNormalization()(x)\n",
    "    if acti_fn=='relu':\n",
    "        x = ReLU()(x)\n",
    "    elif acti_fn=='prelu':\n",
    "        x = PReLU(shared_axes=[1,2,3])(x)\n",
    "    if dropout_rate != None:\n",
    "        x = Dropout(dropout_rate)(x)\n",
    "    x = Conv3D(filters[0], kernel_size, padding='same', kernel_initializer=kernel_initializer)(x)\n",
    "    #2nd convolutional block\n",
    "    if norm_fn=='bn':\n",
    "        x = BatchNormalization()(x)\n",
    "    elif norm_fn=='gn':\n",
    "        x = GroupNormalization()(x)\n",
    "    if acti_fn=='relu':\n",
    "        x = ReLU()(x)\n",
    "    elif acti_fn=='prelu':\n",
    "        x = PReLU(shared_axes=[1,2,3])(x)\n",
    "    x = Conv3D(filters[1], kernel_size, padding='same', kernel_initializer=kernel_initializer)(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def down_sampling_3D(x, filters, norm_fn='gn', kernel_size=3, acti_fn='relu',\n",
    "            kernel_initializer=hn, dropout_rate=None):\n",
    "    '''\n",
    "    Down sampling function version 2 with Convolutional layer of stride 2 as downsampling operation, with\n",
    "    [full pre-activation], Norm -> Acti -> Conv\n",
    "    :param x: Input features\n",
    "    :param filters: Number of filters for Convolutional layer of stride 2\n",
    "    :param norm_fn: Tensorflow function for normalization, 'bn' for Batch Norm, 'gn' for Group Norm\n",
    "    :param kernel_size: Kernel size for both convolutional layer with 3x3 as default\n",
    "    :param acti_fn: Tensorflow function for activation, 'relu' for ReLU, 'prelu' for PReLU\n",
    "    :param kernel_initializer: Initializer for kernel weights with 'glorot uniform' as default\n",
    "    :param dropout_rate: Specify dropouts for layers\n",
    "    :return: Feature maps of size scaled down by 2 with number of filters specified\n",
    "    '''\n",
    "    assert acti_fn!= None, 'There should be an activation function specified'\n",
    "    #normalization\n",
    "    if norm_fn=='bn':\n",
    "        x = BatchNormalization()(x)\n",
    "    elif norm_fn=='gn':\n",
    "        x = GroupNormalization()(x)\n",
    "    if acti_fn=='relu':\n",
    "        x = ReLU()(x)\n",
    "    #activation\n",
    "    elif acti_fn=='prelu':\n",
    "        x = PReLU(shared_axes=[1,2,3])(x)\n",
    "    if dropout_rate != None:\n",
    "        x = Dropout(dropout_rate)(x)\n",
    "    #normal mode\n",
    "    x = Conv3D(filters, kernel_size, strides=(1,2,2), padding='same', kernel_initializer=kernel_initializer)(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def res_block_3D(x_in, filters, norm_fn='gn', kernel_size=3,\n",
    "               kernel_initializer=hn, acti_fn='prelu', dropout_rate=None):\n",
    "    '''\n",
    "    This function construct the residual block in 3D by input->conv_block_3D->concat([input,conv_output])\n",
    "    :param x: Input features\n",
    "    :param filters: A list that contains the number of filters for 1st and 2nd convolutional layer\n",
    "    :param norm_fn: Tensorflow function for normalization, 'bn' for Batch Norm, 'gn' for Group Norm\n",
    "    :param kernel_size: Kernel size for both convolutional layer with 3x3 as default\n",
    "    :param kernel_initializer: Initializer for kernel weights with 'glorot uniform' as default\n",
    "    :param acti_fn: Tensorflow function for activation, 'relu' for ReLU, 'prelu' for PReLU\n",
    "    :param dropout_rate: Specify dropouts for layers\n",
    "    :return: Resblock output => concatenating input with 2*convlutional output\n",
    "    '''\n",
    "    assert len(filters)==2, \"Please assure that there is 2 values for filters.\"\n",
    "    output_conv_block = conv_block_3D(x_in, filters, norm_fn=norm_fn, kernel_size=kernel_size,\n",
    "                                   kernel_initializer = kernel_initializer, acti_fn = acti_fn, dropout_rate=dropout_rate)\n",
    "    output_add = Add()([output_conv_block, x_in])\n",
    "    return output_add\n",
    "\n",
    "\n",
    "def up_3D(x_in, filters, merge, kernel_initializer=hn, size=(1, 2, 2)):\n",
    "    '''\n",
    "    This function carry out the operation of deconvolution => upsampling + convolution, and\n",
    "    concatenating feture maps from the skip connection with the deconv feature maps\n",
    "    @param x_in: input feature\n",
    "    @param filters: Number of filters\n",
    "    @param merge: featrure maps from the skip connection\n",
    "    @param kernel_initializer: Initializer for kernel weights with 'glorot uniform' as default\n",
    "    @param size: Upsampling size, by default (1,2,2)\n",
    "    @return: concatenate feature maps of skip connection output and upsampled feature maps from previous output\n",
    "    '''\n",
    "    u = UpSampling3D(size)(x_in)\n",
    "    conv = Conv3D(filters=filters, kernel_size=3, padding='same', kernel_initializer=kernel_initializer)(u)\n",
    "    conv = PReLU(shared_axes=[1,2,3])(conv)\n",
    "    concat = tf.concat([merge, conv], axis=-1)\n",
    "    return concat\n",
    "\n",
    "def vnet(x):\n",
    "    # inject gaussian noise\n",
    "    gauss1 = GaussianNoise(0.01)(x)\n",
    "    # -----------down sampling path--------------------------------------\n",
    "    # 1st block [155, 200, 200, 4]\n",
    "    conv_01 = Conv3D(16, 3, padding='same', kernel_initializer=hn)(gauss1)\n",
    "    conv_01 = PReLU(shared_axes=[1,2,3])(conv_01)\n",
    "    res_block01 = conv_block_3D(conv_01, filters=[32, 16])\n",
    "    # 2nd block [155, 100, 100, 4]\n",
    "    down_01 = down_sampling_3D(res_block01,filters=32)\n",
    "    res_block02 = res_block_3D(down_01, filters=[64, 32])\n",
    "    # 3rd block [155, 50, 50, 4]\n",
    "    down_02 = down_sampling_3D(res_block02,filters=64)\n",
    "    res_block03 = res_block_3D(down_02, filters=[128, 64])\n",
    "    # 4th block [155, 25, 25, 4] *latent space\n",
    "    down_03 = down_sampling_3D(res_block03,filters=128)\n",
    "    res_block04 = res_block_3D(down_03, filters=[256, 128])\n",
    "\n",
    "    # -----------up sampling path-----------------------------------------\n",
    "    # 1st up [155, 50, 50, 4]\n",
    "    up_01 = up_3D(res_block04, 64, res_block03)\n",
    "    up_conv01 = conv_block_3D(up_01, filters=[128, 128])\n",
    "    # 2nd up [155, 100, 100, 4]\n",
    "    up_02 = up_3D(up_conv01, 64, res_block02)\n",
    "    up_conv02 = conv_block_3D(up_02, filters=[64, 64])\n",
    "    # 3rd up [155, 200, 200, 4]\n",
    "    up_03 = up_3D(up_conv02, 64, res_block01)\n",
    "    up_conv03 = conv_block_3D(up_03, filters=[64, 64])\n",
    "\n",
    "    #segmentation output\n",
    "    output = Conv3D(4,kernel_size=1, activation='softmax',\n",
    "                    kernel_initializer=hn)(up_conv03)\n",
    "    return output"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "input_layer = Input(shape=(150,200,200,4))\n",
    "model = Model(input_layer, vnet(input_layer))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 150, 200, 20 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise (GaussianNoise)  (None, 150, 200, 200 0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_22 (Conv3D)              (None, 150, 200, 200 1744        gaussian_noise[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_18 (PReLU)              (None, 150, 200, 200 16          conv3d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "group_normalization_17 (GroupNo (None, 150, 200, 200 32          p_re_lu_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_19 (PReLU)              (None, 150, 200, 200 16          group_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_23 (Conv3D)              (None, 150, 200, 200 13856       p_re_lu_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "group_normalization_18 (GroupNo (None, 150, 200, 200 64          conv3d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_20 (PReLU)              (None, 150, 200, 200 32          group_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_24 (Conv3D)              (None, 150, 200, 200 13840       p_re_lu_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "group_normalization_19 (GroupNo (None, 150, 200, 200 32          conv3d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_3 (ReLU)                  (None, 150, 200, 200 0           group_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_25 (Conv3D)              (None, 150, 100, 100 13856       re_lu_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "group_normalization_20 (GroupNo (None, 150, 100, 100 64          conv3d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_21 (PReLU)              (None, 150, 100, 100 32          group_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_26 (Conv3D)              (None, 150, 100, 100 55360       p_re_lu_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "group_normalization_21 (GroupNo (None, 150, 100, 100 128         conv3d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_22 (PReLU)              (None, 150, 100, 100 64          group_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_27 (Conv3D)              (None, 150, 100, 100 55328       p_re_lu_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 150, 100, 100 0           conv3d_27[0][0]                  \n",
      "                                                                 conv3d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "group_normalization_22 (GroupNo (None, 150, 100, 100 64          add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_4 (ReLU)                  (None, 150, 100, 100 0           group_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_28 (Conv3D)              (None, 150, 50, 50,  55360       re_lu_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "group_normalization_23 (GroupNo (None, 150, 50, 50,  128         conv3d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_23 (PReLU)              (None, 150, 50, 50,  64          group_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_29 (Conv3D)              (None, 150, 50, 50,  221312      p_re_lu_23[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "group_normalization_24 (GroupNo (None, 150, 50, 50,  256         conv3d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_24 (PReLU)              (None, 150, 50, 50,  128         group_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_30 (Conv3D)              (None, 150, 50, 50,  221248      p_re_lu_24[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 150, 50, 50,  0           conv3d_30[0][0]                  \n",
      "                                                                 conv3d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "group_normalization_25 (GroupNo (None, 150, 50, 50,  128         add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_5 (ReLU)                  (None, 150, 50, 50,  0           group_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_31 (Conv3D)              (None, 150, 25, 25,  221312      re_lu_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "group_normalization_26 (GroupNo (None, 150, 25, 25,  256         conv3d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_25 (PReLU)              (None, 150, 25, 25,  128         group_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_32 (Conv3D)              (None, 150, 25, 25,  884992      p_re_lu_25[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "group_normalization_27 (GroupNo (None, 150, 25, 25,  512         conv3d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_26 (PReLU)              (None, 150, 25, 25,  256         group_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_33 (Conv3D)              (None, 150, 25, 25,  884864      p_re_lu_26[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 150, 25, 25,  0           conv3d_33[0][0]                  \n",
      "                                                                 conv3d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling3d_3 (UpSampling3D)  (None, 150, 50, 50,  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_34 (Conv3D)              (None, 150, 50, 50,  221248      up_sampling3d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_27 (PReLU)              (None, 150, 50, 50,  64          conv3d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_3 (TensorFlo [(None, 150, 50, 50, 0           add_4[0][0]                      \n",
      "                                                                 p_re_lu_27[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "group_normalization_28 (GroupNo (None, 150, 50, 50,  256         tf_op_layer_concat_3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_28 (PReLU)              (None, 150, 50, 50,  128         group_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_35 (Conv3D)              (None, 150, 50, 50,  442496      p_re_lu_28[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "group_normalization_29 (GroupNo (None, 150, 50, 50,  256         conv3d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_29 (PReLU)              (None, 150, 50, 50,  128         group_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_36 (Conv3D)              (None, 150, 50, 50,  442496      p_re_lu_29[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling3d_4 (UpSampling3D)  (None, 150, 100, 100 0           conv3d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_37 (Conv3D)              (None, 150, 100, 100 221248      up_sampling3d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_30 (PReLU)              (None, 150, 100, 100 64          conv3d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_4 (TensorFlo [(None, 150, 100, 10 0           add_3[0][0]                      \n",
      "                                                                 p_re_lu_30[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "group_normalization_30 (GroupNo (None, 150, 100, 100 192         tf_op_layer_concat_4[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_31 (PReLU)              (None, 150, 100, 100 96          group_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_38 (Conv3D)              (None, 150, 100, 100 165952      p_re_lu_31[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "group_normalization_31 (GroupNo (None, 150, 100, 100 128         conv3d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_32 (PReLU)              (None, 150, 100, 100 64          group_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_39 (Conv3D)              (None, 150, 100, 100 110656      p_re_lu_32[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling3d_5 (UpSampling3D)  (None, 150, 200, 200 0           conv3d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_40 (Conv3D)              (None, 150, 200, 200 110656      up_sampling3d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_33 (PReLU)              (None, 150, 200, 200 64          conv3d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_5 (TensorFlo [(None, 150, 200, 20 0           conv3d_24[0][0]                  \n",
      "                                                                 p_re_lu_33[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "group_normalization_32 (GroupNo (None, 150, 200, 200 160         tf_op_layer_concat_5[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_34 (PReLU)              (None, 150, 200, 200 80          group_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_41 (Conv3D)              (None, 150, 200, 200 138304      p_re_lu_34[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "group_normalization_33 (GroupNo (None, 150, 200, 200 128         conv3d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_35 (PReLU)              (None, 150, 200, 200 64          group_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_42 (Conv3D)              (None, 150, 200, 200 110656      p_re_lu_35[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_43 (Conv3D)              (None, 150, 200, 200 260         conv3d_42[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 4,611,316\n",
      "Trainable params: 4,611,316\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}