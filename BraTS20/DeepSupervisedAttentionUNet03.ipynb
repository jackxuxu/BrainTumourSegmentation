{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kevinteng/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/kevinteng/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/kevinteng/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/kevinteng/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/kevinteng/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/kevinteng/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import time\n",
    "sys.path.append('/home/kevinteng/Desktop/BrainTumourSegmentation')\n",
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os, random\n",
    "import utils\n",
    "from utils_vis import plot_comparison, plot_labels_color \n",
    "from utils import dice_coef, ss_metric, compute_metric\n",
    "import nibabel as nib\n",
    "from sklearn.model_selection import KFold\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Blue => Label 1 (Necrotic and Non-enhancing Tumor Core)\n",
    "- Yellow => Label 2 (Peritumoral Edema)\n",
    "- Green => Label 3/4 (GD-Enhancing Tumor)\n",
    "---\n",
    "* Core => Label 1 & 3\n",
    "* Enhancing => Label 3\n",
    "* Complete => Label 1,2, 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHUFFLE_BUFFER = 4000\n",
    "max_epochs = 2\n",
    "BATCH_SIZE = 24\n",
    "lr = 0.00001\n",
    "opt = tf.keras.optimizers.Adam(lr)\n",
    "ver = 'DeepSupervisedAttentionUNet03' #save version \n",
    "dropout=0.3 #dropout rate\n",
    "hn = 'he_normal' #kernel initializer \n",
    "tfrecords_read_dir = '/home/kevinteng/Desktop/ssd02/BraTS20_tfrecords03/'\n",
    "stack_npy = \"/home/kevinteng/Desktop/ssd02/BraTS2020_stack03/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "xent = tf.keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "def generalized_dice(y_true, y_pred, smooth = 1e-5):\n",
    "    \"\"\"\n",
    "    Generalized Dice Score\n",
    "    https://arxiv.org/pdf/1707.03237\n",
    "    https://github.com/Mehrdad-Noori/Brain-Tumor-Segmentation/blob/master/loss.py\n",
    "    \"\"\"\n",
    "    \n",
    "    y_true    = tf.reshape(y_true,shape=(-1,4))\n",
    "    y_pred    = tf.reshape(y_pred,shape=(-1,4))\n",
    "    sum_p     = tf.reduce_sum(y_pred, -2)\n",
    "    sum_r     = tf.reduce_sum(y_true, -2)\n",
    "    sum_pr    = tf.reduce_sum(y_true * y_pred, -2)\n",
    "    weights   = tf.math.pow(tf.math.square(sum_r) + smooth, -1)\n",
    "    generalized_dice = (2 * tf.reduce_sum(weights * sum_pr)) / (tf.reduce_sum(weights * (sum_r + sum_p)))\n",
    "    return generalized_dice\n",
    "\n",
    "def generalized_dice_loss(y_true, y_pred):   \n",
    "    return 1-generalized_dice(y_true, y_pred)\n",
    "    \n",
    "def custom_loss(y_true, y_pred):\n",
    "    \n",
    "    \"\"\"\n",
    "    The final loss function consists of the summation of two losses \"GDL\" and \"CE\"\n",
    "    with a regularization term.\n",
    "    \"\"\"\n",
    "    \n",
    "    return generalized_dice_loss(y_true, y_pred) + 1.25 * xent(y_true, y_pred)\n",
    "\n",
    "def data_aug(imgs, seed=8888):\n",
    "    x = tf.image.random_flip_up_down(imgs,seed)\n",
    "    x = tf.image.random_flip_left_right(x,seed)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_model import conv_block, coordconv_block, up, pool, attention_block\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, UpSampling2D, Activation, Add, Multiply, GaussianNoise\n",
    "\n",
    "def AttUnet_model(input_layer, attention_mode='grid'):\n",
    "    gauss1 = GaussianNoise(0.01)(input_layer)\n",
    "    #downsampling path\n",
    "    conv1 = conv_block(gauss1, filters=64, kernel_initializer=hn)\n",
    "    pool1 = pool(conv1)\n",
    "    \n",
    "    conv2 = conv_block(pool1, filters=128, kernel_initializer=hn)\n",
    "    pool2 = pool(conv2)\n",
    "    \n",
    "    conv3 = conv_block(pool2, filters=256, kernel_initializer=hn)\n",
    "    pool3 = pool(conv3)\n",
    "    \n",
    "    conv4 = conv_block(pool3, filters=512, kernel_initializer=hn)\n",
    "    pool4 = pool(conv4)\n",
    "    \n",
    "    conv5 = conv_block(pool4, filters=1024, kernel_initializer=hn)\n",
    "    \n",
    "    #upsampling path\n",
    "    att01 = attention_block(conv4, conv5, 512)\n",
    "    up1 = up(conv5,filters=512, merge=att01, kernel_initializer=hn)\n",
    "    conv6 = conv_block(up1, filters=512, kernel_initializer=hn)\n",
    "    \n",
    "    if attention_mode=='grid':\n",
    "        att02 = attention_block(conv3, conv6, 256)\n",
    "    else:\n",
    "        att02 = attention_block(conv3, conv4, 256)\n",
    "    up2 = up(conv6, filters=256, merge=att02, kernel_initializer=hn)\n",
    "    conv7 = conv_block(up2, filters=256, kernel_initializer=hn)\n",
    "    #injection block 1\n",
    "    seg01 = Conv2D(4,(1,1),padding='same')(conv7)\n",
    "    up_seg01 = UpSampling2D()(seg01)\n",
    "    \n",
    "    if attention_mode=='grid':\n",
    "        att03 = attention_block(conv2, conv7, 128)\n",
    "    else:\n",
    "        att03 = attention_block(conv2, conv3, 128)\n",
    "    up3 = up(conv7, filters=128, merge=att03, kernel_initializer=hn)\n",
    "    conv8 = conv_block(up3, filters=128, kernel_initializer=hn)\n",
    "    #injection block 2\n",
    "    seg02 = Conv2D(4,(1,1),padding='same')(conv8)\n",
    "    add_21 = Add()([seg02, up_seg01])\n",
    "    up_seg02 = UpSampling2D()(add_21)\n",
    "    \n",
    "    if attention_mode=='grid':\n",
    "        att04 = attention_block(conv1, conv8, 64)\n",
    "    else:\n",
    "        att04 = attention_block(conv1, conv2, 64)\n",
    "    up4 = up(conv8, filters=64, merge=att04, kernel_initializer=hn)\n",
    "    conv9 = conv_block(up4, filters=64, kernel_initializer=hn)\n",
    "    #injection block 3\n",
    "    seg03 = Conv2D(4,(1,1),padding='same')(conv9)\n",
    "    add_32 = Add()([seg03, up_seg02])\n",
    "    \n",
    "    output_layer = Conv2D(4, (1,1), activation = 'softmax')(add_32)\n",
    "    \n",
    "    return output_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Build Model\n",
    "input_layer = Input(shape=(240,240,4))\n",
    "model = Model(input_layer, AttUnet_model(input_layer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_fn(image, label):\n",
    "    with tf.GradientTape() as tape:\n",
    "        model_output = model(image, training=True)\n",
    "        loss = custom_loss(label, model_output)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    opt.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    \n",
    "    return model_output, loss, gradients\n",
    "\n",
    "@tf.function\n",
    "def val_fn(image, label):\n",
    "    model_output = model(image, training=False)\n",
    "    loss = custom_loss(label, model_output)\n",
    "    return model_output, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 1\n",
      "Epochs  1\n"
     ]
    }
   ],
   "source": [
    "ds = os.listdir(tfrecords_read_dir)\n",
    "kf = KFold(n_splits=len(ds),shuffle=True)\n",
    "folds = 1\n",
    "for train_id, val_id in kf.split(ds):\n",
    "    print(\"Fold: {}\".format(folds))\n",
    "    epochs=1\n",
    "    start = time.time()\n",
    "    #list for training \n",
    "    loss_list = []\n",
    "    acc_list = []\n",
    "    loss_inner = []\n",
    "    #for every fold we run(<=max_epochs)\n",
    "    while epochs <= max_epochs:\n",
    "        print(\"Epochs {:2d}\".format(epochs))\n",
    "        steps=1\n",
    "        #training fold\n",
    "        for idx in train_id:\n",
    "            acc_inner = []\n",
    "            dc_app = []\n",
    "            sens_app = []\n",
    "            spec_app = []\n",
    "            train_tf = ds[idx]\n",
    "            tf_dir = os.path.join(tfrecords_read_dir+train_tf)\n",
    "            dataset = utils.parse_tfrecord(tf_dir).shuffle(SHUFFLE_BUFFER).batch(BATCH_SIZE)     \n",
    "            for imgs in dataset:\n",
    "                #data augmentation\n",
    "                imgs = data_aug(imgs)\n",
    "                image = imgs[:,:,:,:4]\n",
    "                #unprocessed label for plotting \n",
    "                label = imgs[:,:,:,-1]\n",
    "                #for simplicity label 4 will be converted to 3 for sparse encoding\n",
    "                label = tf.where(label==4,3,label)\n",
    "                label = tf.keras.utils.to_categorical(label, num_classes=4)\n",
    "                img_seg, loss, gradients = train_fn(image, label) #training function \n",
    "                #map from sparse to label\n",
    "                img_seg = tf.math.argmax(img_seg,-1,output_type=tf.int32) \n",
    "                label = tf.math.argmax(label,-1,output_type=tf.int32)\n",
    "                #accuracy of the output values for that batch\n",
    "                acc = tf.reduce_mean(tf.cast(tf.equal(img_seg,label), tf.float32))\n",
    "                #append accuracy for every steps\n",
    "                acc_inner.append(acc)\n",
    "                #accumulate dc score, sensitivity and specificity \n",
    "                dc_list, sens_list, spec_list =compute_metric(label,img_seg)\n",
    "                dc_app.append(dc_list)\n",
    "                sens_app.append(sens_list)\n",
    "                spec_app.append(spec_list)\n",
    "                #output\n",
    "                if steps%1000==0:\n",
    "                    input_img = [image[0,:,:,0], plot_labels_color(label[0]), plot_labels_color(img_seg[0])]\n",
    "                    caption = ['Input Image', 'Ground Truth', 'Model Output']\n",
    "                    plot_comparison(input_img, caption, n_col = 3, figsize=(10,10), captions_font = 10)\n",
    "                    loss_list.append(loss)\n",
    "                    acc_stp = tf.reduce_mean(tf.cast(tf.equal(img_seg[0],label[0]), tf.float32))\n",
    "                    dc_list_stp, sens_list_stp, spec_list_stp =compute_metric(label[0],img_seg[0])\n",
    "                    print(\"Steps: {}, Loss:{}\".format(steps, loss))\n",
    "                    print(\"Accurary: {}\".format(acc_stp))\n",
    "                    print(\"Dice coefficient: {}\".format(dc_list_stp))\n",
    "                    print(\"Sensitivity: {}\".format(sens_list_stp))\n",
    "                    print(\"Specificity: {}\".format(spec_list_stp))\n",
    "                    print(\"Gradient min:{}, max:{}\".format(np.min(gradients[0]), np.max(gradients[0])))\n",
    "                steps+=1\n",
    "        acc_list.append(np.mean(acc_inner))\n",
    "        mean_dc = np.mean(np.array(dc_app),0)\n",
    "        mean_sens = np.mean(np.array(sens_app),0)\n",
    "        mean_spec = np.mean(np.array(spec_app),0)\n",
    "        print()\n",
    "        print('-----------<Training summary for Epoch:{}>------------'.format(epochs))\n",
    "        print(\"Mean Accuracy: {}\".format(np.mean(acc_list)))\n",
    "        #'core','enhancing','complete'\n",
    "        print(\"Mean Dice coefficient: {}\".format(mean_dc))\n",
    "        print(\"Mean Sensitivity: {}\".format(mean_sens))\n",
    "        print(\"Mean Specificity: {}\".format(mean_spec))\n",
    "        print('------------------------------------------------')\n",
    "        print()\n",
    "        #validation\n",
    "        acc_inner_val=[]\n",
    "        dc_app_val = []\n",
    "        sens_app_val = []\n",
    "        spec_app_val = []\n",
    "        val_tf = ds[val_id[0]]\n",
    "        val_tf_dir = os.path.join(tfrecords_read_dir+val_tf)\n",
    "        val_ds = utils.parse_tfrecord(val_tf_dir).shuffle(SHUFFLE_BUFFER).batch(BATCH_SIZE)\n",
    "        for imgs in val_ds:\n",
    "            image = imgs[:,:,:,:4]\n",
    "            label = imgs[:,:,:,-1]\n",
    "            label = tf.where(label==4,3,label)\n",
    "            label = tf.keras.utils.to_categorical(label, num_classes=4)\n",
    "            val_img_seg, val_loss = val_fn(image, label)\n",
    "            val_img_seg = tf.math.argmax(val_img_seg,-1,output_type=tf.int32) \n",
    "            label = tf.math.argmax(label,-1,output_type=tf.int32)\n",
    "            acc = tf.reduce_mean(tf.cast(tf.equal(val_img_seg,label), tf.float32))\n",
    "            #append accuracy for every steps\n",
    "            acc_inner_val.append(acc)\n",
    "            #accumulate dc score, sensitivity and specificity \n",
    "            dc_list, sens_list, spec_list =compute_metric(label,val_img_seg)\n",
    "            dc_app_val.append(dc_list)\n",
    "            sens_app_val.append(sens_list)\n",
    "            spec_app_val.append(spec_list)\n",
    "            \n",
    "        acc_list_val = np.mean(acc_inner)\n",
    "        mean_dc = np.mean(np.array(dc_app_val),0)\n",
    "        mean_sens = np.mean(np.array(sens_app_val),0)\n",
    "        mean_spec = np.mean(np.array(spec_app_val),0)\n",
    "        print()\n",
    "        print('-----------<Validation summary for Epoch:{}>------------'.format(epochs))\n",
    "        print(\"Mean Accuracy: {}\".format(np.mean(acc_list_val)))\n",
    "        #'core','enhancing','complete'\n",
    "        print(\"Mean Dice coefficient: {}\".format(mean_dc))\n",
    "        print(\"Mean Sensitivity: {}\".format(mean_sens))\n",
    "        print(\"Mean Specificity: {}\".format(mean_spec))\n",
    "        print('------------------------------------------------')\n",
    "        print()\n",
    "        \n",
    "        elapsed_time =(time.time()-start)/60 #unit in mins\n",
    "        print(\"Compute time per epochs: {:.2f} mins\".format(elapsed_time))\n",
    "        epochs+=1 \n",
    "    folds+=1\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('/home/kevinteng/Desktop/model_weights/model_{}.h5'.format(ver))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('/home/kevinteng/Desktop/model_weights/model_{}.h5'.format(ver))\n",
    "def output_fn(image):\n",
    "    model.trainable = False\n",
    "    model_output = model(image)\n",
    "    return model_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# ds = '/home/kevinteng/Desktop/ssd02/BraTS2020_preprocessed03/'\n",
    "# save_path = '/home/kevinteng/Desktop/ssd02/submission/'\n",
    "# actual_label = '/home/kevinteng/Desktop/ssd02/MICCAI_BraTS2020_TrainingData/BraTS20_Training_001/BraTS20_Training_001_seg.nii.gz'\n",
    "# #all brain affine are the same just pick one \n",
    "# brain_affine = nib.load(actual_label).affine\n",
    "# steps = 1\n",
    "# acc_list = []\n",
    "# for train_or_val in sorted(os.listdir(ds)):\n",
    "#     save_dir = save_path + train_or_val+'_'+ver\n",
    "#     if not os.path.exists(save_dir):\n",
    "#         os.makedirs(save_dir)\n",
    "#     merge01 = os.path.join(ds+train_or_val)\n",
    "#     for patient in sorted(os.listdir(merge01)):\n",
    "#         patient_id = patient.split('.')[0]\n",
    "#         merge02 = os.path.join(merge01,patient)\n",
    "#         imgs = np.load(merge02)\n",
    "#         image = imgs[:,:,:,:4]\n",
    "#         seg_output = 0 #flush RAM\n",
    "#         seg_output = np.zeros((240,240,155))\n",
    "#         for i in range(image.shape[0]):\n",
    "#             inp = tf.expand_dims(image[i],0)\n",
    "#             img_seg = output_fn(inp) #validation function \n",
    "#             #map from sparse to label\n",
    "#             seg_output[:,:,i] = np.argmax(img_seg,-1) \n",
    "#         #convert label from 4 to 3 and np array and cast as int\n",
    "#         seg_output= np.where(seg_output==3,4,seg_output).astype(np.uint8)\n",
    "#         prediction_ni = nib.Nifti1Image(seg_output, brain_affine)\n",
    "#         prediction_ni.to_filename(save_dir+'/{}.nii.gz'.format(patient_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
