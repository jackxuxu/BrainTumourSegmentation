{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "sys.path.append('/home/kevinteng/Desktop/BrainTumourSegmentation')\n",
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os, random\n",
    "import utils\n",
    "from utils_vis import plot_comparison, plot_labels_color \n",
    "from utils import compute_metric_dc\n",
    "import nibabel as nib\n",
    "from sklearn.model_selection import KFold\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Blue => Label 1 (Necrotic and Non-enhancing Tumor Core)\n",
    "- Yellow => Label 2 (Peritumoral Edema)\n",
    "- Green => Label 3/4 (GD-Enhancing Tumor)\n",
    "---\n",
    "* Core => Label 1 & 3\n",
    "* Enhancing => Label 3\n",
    "* Complete => Label 1,2, 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHUFFLE_BUFFER = 4000\n",
    "max_epochs = 20\n",
    "BATCH_SIZE = 8\n",
    "lr = 0.001\n",
    "opt = tf.keras.optimizers.Adam(lr)\n",
    "ver = 'model_self_attention_03' #save version\n",
    "dropout=0.2 #dropout rate\n",
    "hn = 'he_normal' #kernel initializer \n",
    "tfrecords_read_dir = '/home/kevinteng/Desktop/ssd02/BraTS20_tfrecords05/'\n",
    "stack_npy = \"/home/kevinteng/Desktop/ssd02/BraTS2020_stack05/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "xent = tf.keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "def generalized_dice(y_true, y_pred, smooth = 1e-5):\n",
    "    \"\"\"\n",
    "    Generalized Dice Score\n",
    "    https://arxiv.org/pdf/1707.03237\n",
    "    https://github.com/Mehrdad-Noori/Brain-Tumor-Segmentation/blob/master/loss.py\n",
    "    \"\"\"\n",
    "    \n",
    "    y_true    = tf.reshape(y_true,shape=(-1,4))\n",
    "    y_pred    = tf.reshape(y_pred,shape=(-1,4))\n",
    "    sum_p     = tf.reduce_sum(y_pred, -2)\n",
    "    sum_r     = tf.reduce_sum(y_true, -2)\n",
    "    sum_pr    = tf.reduce_sum(y_true * y_pred, -2)\n",
    "    weights   = tf.math.pow(tf.math.square(sum_r) + smooth, -1)\n",
    "    generalized_dice = (2 * tf.reduce_sum(weights * sum_pr)) / (tf.reduce_sum(weights * (sum_r + sum_p)))\n",
    "    return generalized_dice\n",
    "\n",
    "def generalized_dice_loss(y_true, y_pred):   \n",
    "    return 1-generalized_dice(y_true, y_pred)\n",
    "    \n",
    "def custom_loss(y_true, y_pred):\n",
    "    \n",
    "    \"\"\"\n",
    "    The final loss function consists of the summation of two losses \"GDL\" and \"CE\"\n",
    "    with a regularization term.\n",
    "    \"\"\"\n",
    "    \n",
    "    return generalized_dice_loss(y_true, y_pred) + 1.25 * xent(y_true, y_pred)\n",
    "\n",
    "def data_aug(imgs, seed=8888):\n",
    "    x = tf.image.random_flip_up_down(imgs,seed)\n",
    "    x = tf.image.random_flip_left_right(x,seed)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Layer Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# template for guided attention block\n",
    "layer_name_p01 = ['pam01_conv01', 'pam01_conv02', 'pam01_softmax', 'pam01_conv03',\n",
    "                  'pam01_alpha','pam01_add']\n",
    "layer_name_c01 = ['cam01_softmax', 'cam01_alpha','cam01_add']\n",
    "layer_name_p02 = ['pam02_conv01', 'pam02_conv02', 'pam02_softmax', 'pam02_conv03',\n",
    "                  'pam02_alpha', 'pam02_add']\n",
    "layer_name_c02 = ['cam02_softmax', 'cam02_alpha','cam02_add']\n",
    "layer_name_template = [layer_name_p01, layer_name_c01, layer_name_p02, layer_name_c02]\n",
    "\n",
    "layer_name_ga = []\n",
    "for b in range(1,4):\n",
    "    layer_block = []\n",
    "    for layer in layer_name_template:\n",
    "        layer_internal = [i+'block0{}'.format(b) for i in layer]\n",
    "        layer_block.append(layer_internal)\n",
    "    layer_name_ga.append(layer_block)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, UpSampling2D, Activation, Add, Multiply, GaussianNoise\n",
    "from tensorflow.keras.layers import SeparableConv2D, BatchNormalization, Dropout, concatenate\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Layer, Softmax, ReLU, PReLU\n",
    "from tensorflow_addons.layers import GroupNormalization\n",
    "from utils_model import *\n",
    "from attention import *\n",
    "\n",
    "def conv_block_sep_v2(x, filters, layer_name, norm_fn='bn', kernel_size=(3, 3),\n",
    "               kernel_initializer='glorot_uniform', acti_fn='relu', dropout_rate=None):\n",
    "    '''\n",
    "    Dual convolution block with [full pre-activation], Norm -> Acti -> Conv\n",
    "    :param x: Input features\n",
    "    :param filters: A list that contains the number of filters for 1st and 2nd convolutional layer\n",
    "    :param layer_name: A list  that contains the name for the 1st and 2nd convolutional layer\n",
    "    :param norm_fn: Tensorflow function for normalization, 'bn' for Batch Norm, 'gn' for Group Norm\n",
    "    :param kernel_size: Kernel size for both convolutional layer with 3x3 as default\n",
    "    :param kernel_initializer: Initializer for kernel weights with 'glorot uniform' as default\n",
    "    :param acti_fn: Tensorflow function for activation, 'relu' for ReLU, 'prelu' for PReLU\n",
    "    :param dropout_rate: Specify dropouts for layers\n",
    "    :return: Feature maps of same size as input with number of filters equivalent to the last layer\n",
    "    '''\n",
    "    assert type(filters)==list, \"Please input filters of type list.\"\n",
    "    assert type(layer_name)==list, \"Please input filters of type list.\"\n",
    "    assert acti_fn!= None, 'There should be an activation functino specified'\n",
    "    #1st convolutional block\n",
    "    if norm_fn=='bn':\n",
    "        x = BatchNormalization()(x)\n",
    "    elif norm_fn=='gn':\n",
    "        x = GroupNormalization()(x)\n",
    "    if acti_fn=='relu':\n",
    "        x = ReLU()(x)\n",
    "    elif acti_fn=='prelu':\n",
    "        x = PReLU(shared_axes=[1,2])(x)\n",
    "    x = SeparableConv2D(filters[0], kernel_size, padding='same', kernel_initializer=kernel_initializer, name = layer_name[0])(x)\n",
    "    if dropout_rate != None:\n",
    "        x = Dropout(dropout_rate)(x)\n",
    "    #2nd convolutional block\n",
    "    if norm_fn=='bn':\n",
    "        x = BatchNormalization()(x)\n",
    "    elif norm_fn=='gn':\n",
    "        x = GroupNormalization()(x)\n",
    "    if acti_fn=='relu':\n",
    "        x = ReLU()(x)\n",
    "    elif acti_fn=='prelu':\n",
    "        x = PReLU(shared_axes=[1,2])(x)\n",
    "    x = SeparableConv2D(filters[1], kernel_size, padding='same', kernel_initializer=kernel_initializer, name = layer_name[1])(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def down_sampling_sep_v2(x, filters, layer_name, norm_fn='bn', kernel_size=(3, 3), acti_fn='relu',\n",
    "            kernel_initializer='glorot_uniform', dropout_rate=None, mode ='coord', x_dim=None, y_dim=None):\n",
    "    '''\n",
    "    Down sampling function version 2 with Convolutional layer of stride 2 as downsampling operation, with\n",
    "    [full pre-activation], Norm -> Acti -> Conv\n",
    "    :param x: Input features\n",
    "    :param filters: Number of filters for Convolutional layer of stride 2\n",
    "    :param layer_name: Layer name for convolutional layer\n",
    "    :param norm_fn: Tensorflow function for normalization, 'bn' for Batch Norm, 'gn' for Group Norm\n",
    "    :param kernel_size: Kernel size for both convolutional layer with 3x3 as default\n",
    "    :param acti_fn: Tensorflow function for activation, 'relu' for ReLU, 'prelu' for PReLU\n",
    "    :param kernel_initializer: Initializer for kernel weights with 'glorot uniform' as default\n",
    "    :param dropout_rate: Specify dropouts for layers\n",
    "    :param mode: 'coord' for Seperable Coord Conv, 'normal' for Seperable Conv\n",
    "    :param x_dim: x dimension for coord conv\n",
    "    :param y_dim: y dimension for coord conv\n",
    "    :return: Feature maps of size scaled down by 2 with number of filters specified\n",
    "    '''\n",
    "    assert mode=='coord' or mode=='normal',  \"Use 'coord' or 'normal' for mode!\"\n",
    "    assert acti_fn!= None, 'There should be an activation functino specified'\n",
    "    if norm_fn=='bn':\n",
    "        x = BatchNormalization()(x)\n",
    "    elif norm_fn=='gn':\n",
    "        x = GroupNormalization()(x)\n",
    "    if acti_fn=='relu':\n",
    "        x = ReLU()(x)\n",
    "    elif acti_fn=='prelu':\n",
    "        x = PReLU(shared_axes=[1,2])(x)\n",
    "    if mode=='coord':\n",
    "        #seperable coordconv\n",
    "        assert (x_dim!=None and y_dim!=None), \"Please input dimension for CoordConv!\"\n",
    "        x = Conv2D(1, kernel_size, strides=(2, 2), padding='same', kernel_initializer=kernel_initializer)(x)\n",
    "        x = CoordConv(x_dim=x_dim, y_dim=y_dim, with_r=False, filters=filters, strides=(1,1),\n",
    "                      kernel_size = 3, padding='same', kernel_initializer=kernel_initializer, name=layer_name)(x)\n",
    "    else:\n",
    "        #normal mode\n",
    "        x = SeparableConv2D(filters, kernel_size, strides=(2, 2), padding='same', kernel_initializer=kernel_initializer, name=layer_name)(x)\n",
    "    if dropout_rate != None:\n",
    "        x = Dropout(dropout_rate)(x)\n",
    "    return x\n",
    "\n",
    "def res_block_sep_v2(x_in, filters,  layer_name, norm_fn='gn', kernel_size=(3, 3),\n",
    "               kernel_initializer='glorot_uniform', acti_fn='prelu', dropout_rate=None):\n",
    "    assert len(filters)==2, \"Please assure that there is 3 values for filters.\"\n",
    "    assert len(layer_name)==3, \"Please assure that there is 3 values for layer name\"\n",
    "    layer_name_conv = [layer_name[i] for i in range(len(layer_name)-1)]\n",
    "    output_conv_block = conv_block_sep_v2(x_in, filters, layer_name_conv, norm_fn=norm_fn, kernel_size=kernel_size,\n",
    "                                   kernel_initializer = kernel_initializer, acti_fn = acti_fn, dropout_rate=dropout_rate)\n",
    "    output_add = Add(name = layer_name[-1])([output_conv_block, x_in])\n",
    "    return output_add\n",
    "\n",
    "def guided_attention_block(inp_feature, layer_name_p, layer_name_c):\n",
    "    '''\n",
    "    Guided attention block that takes feature as input and concatenates features\n",
    "    from PAM and CAM as output\n",
    "    :param inp_feature: Input features\n",
    "    :param layer_name_p: layer name list for PAM\n",
    "    :param layer_name_c: layer name list for CAM\n",
    "    :return: squeezed concatenated features of PAM and CAM\n",
    "    '''\n",
    "    pam_feature = PAM(inp_feature, layer_name_p, kernel_initializer=hn)\n",
    "    cam_feature = CAM(inp_feature, layer_name_c)\n",
    "    add = Add()([pam_feature,cam_feature]) #[60,60,128]\n",
    "    up = UpSampling2D(size=(4,4))(add) #[240,240,128]\n",
    "    squeeze = Conv2D(filters=64, kernel_size=1, padding='same', kernel_initializer=hn,\n",
    "                       activation='relu')(up)\n",
    "    return squeeze\n",
    "\n",
    "def guided_attention(res_feature, ms_feature, layer_name):\n",
    "    '''\n",
    "    Guided attention module\n",
    "    :param res_feature: Upsampled Feature maps from Res Block\n",
    "    :param ms_feature: Multi scale feature maps result from Res Block\n",
    "    :param layer_name: Layer Name should consist be a list contating 4 list\n",
    "    Example:\n",
    "    layer_name_p01 = ['pam01_conv01', 'pam01_conv02', 'pam01_softmax', 'pam01_conv03',\n",
    "                      'pam01_alpha','pam01_add']\n",
    "    layer_name_c01 = ['cam01_softmax', 'cam01_alpha','cam01_add']\n",
    "    layer_name_p02 = ['pam02_conv01', 'pam02_conv02', 'pam02_softmax', 'pam02_conv03',\n",
    "                      'pam02_alpha', 'pam02_add']\n",
    "    layer_name_c02 = ['cam02_softmax', 'cam02_alpha','cam02_add']\n",
    "    layer_name = [layer_name_p01, layer_name_c01, layer_name_p02, layer_name_c02]\n",
    "\n",
    "    :return: guided attention module with shape same as input\n",
    "    '''\n",
    "    assert len(layer_name)==4, \"Layer name should be a list consisting 4 lists!\"\n",
    "    #self attention block01\n",
    "    concat01 = concatenate([res_feature, ms_feature], axis=-1)\n",
    "    squeeze01 = guided_attention_block(concat01, layer_name[0], layer_name[1])\n",
    "    multi01 = Multiply()([squeeze01, ms_feature])\n",
    "    #self attention block02\n",
    "#     concat02 = concatenate([multi01, res_feature],axis=-1)\n",
    "#     squeeze02 = guided_attention_block(concat02, layer_name[2], layer_name[3])\n",
    "    return multi01\n",
    "\n",
    "def forward(x):\n",
    "    '''\n",
    "    Resnet as backbone for multiscale feature retrieval.\n",
    "    Each resblock output(input signal), next resblock output(gated signal) is\n",
    "    feed into the gated attention for multi scale feature refinement.\n",
    "    Each gated attention output is pass through a bottle neck layer to standardize\n",
    "    the channel size by squashing them to desired filter size of 64.\n",
    "    The features are upsampled at each block to the corresponding [wxh] dimension\n",
    "    of w:240, h:240.\n",
    "    The upsampled features are concat and squash to corresponding channel size of 64\n",
    "    which yield multiscale feature.\n",
    "    :param x: batched images\n",
    "    :return: feature maps of each res block\n",
    "    '''\n",
    "    #inject noise\n",
    "    gauss1 = GaussianNoise(0.01)(x)\n",
    "    #retrieve input dimension\n",
    "    b,w,h,c = x.shape\n",
    "    #---- ResNet and Multiscale Features----\n",
    "    #1st block\n",
    "    conv01 = CoordConv(x_dim=w, y_dim=h, with_r=False, filters=64, strides=(1,1),\n",
    "                      kernel_size = 3, padding='same', kernel_initializer=hn, name='conv01')(gauss1)\n",
    "    res_block01 = res_block_sep_v2(conv01, filters=[128, 64], layer_name=[\"conv02\", \"conv03\", \"add01\"], dropout_rate=dropout)\n",
    "    #2nd block\n",
    "    down_01 = down_sampling_sep_v2(res_block01, filters=128, layer_name = 'down_01',  kernel_initializer=hn,\n",
    "                               mode='normal',x_dim=w//2, y_dim=w//2)\n",
    "    res_block02 = res_block_sep_v2(down_01, filters=[256, 128], layer_name=[\"conv04\", \"conv05\", \"add02\"], dropout_rate=dropout)\n",
    "    #3rd block\n",
    "    down_02 = down_sampling_sep_v2(res_block02, filters=256, layer_name = 'down_02',  kernel_initializer=hn,\n",
    "                               mode='normal',x_dim=w//4, y_dim=h//4)\n",
    "    res_block03 = res_block_sep_v2(down_02, filters=[512, 256], layer_name=[\"conv06\", \"conv07\", \"add03\"], dropout_rate=dropout)\n",
    "    #4th block\n",
    "    down_03 = down_sampling_sep_v2(res_block03, filters=512, layer_name = 'down_03',  kernel_initializer=hn,\n",
    "                               mode='normal',x_dim=w//8, y_dim=h//8)\n",
    "    res_block04 = res_block_sep_v2(down_03, filters=[1024, 512], layer_name=[\"conv08\", \"conv09\", \"add04\"], dropout_rate=dropout)\n",
    "    # *apply activation function for the last output\n",
    "    res_block04 = PReLU(shared_axes=[1,2])(res_block04)\n",
    "    #grid attention blocks\n",
    "    att_block01 = attention_block(res_block01,res_block02,64,'grid_att01')\n",
    "    att_block02 = attention_block(res_block02,res_block03,128,'grid_att02')\n",
    "    att_block03 = attention_block(res_block03, res_block04,256,'gird_att03')\n",
    "    #bottle neck => layer squash all attention block to same filter size 64\n",
    "    bottle01 = Conv2D(filters=64, kernel_size=1, padding='same', kernel_initializer=hn)(att_block01)\n",
    "    bottle02 = Conv2D(filters=64, kernel_size=1, padding='same', kernel_initializer=hn)(att_block02)\n",
    "    bottle03 = Conv2D(filters=64, kernel_size=1, padding='same', kernel_initializer=hn)(att_block03)\n",
    "    #upsampling for all layers to same (wxh) dimension=>240x240\n",
    "    up01 = bottle01 #[240,240,64]\n",
    "    up02 = UpSampling2D(size=(2, 2), interpolation='bilinear')(bottle02) #[120,120,64]=>[240,240,64]\n",
    "    up03 = UpSampling2D(size=(4,4), interpolation='bilinear')(bottle03) #[60,60,64]=>[240,240,64]\n",
    "    #multiscale features\n",
    "    concat_all = concatenate([up01,up02,up03],axis=-1) #[240,240,3*64]\n",
    "    #squeeze to have the same channel as upsampled features [240,240,3*64] => [240,240,64]\n",
    "    ms_feature = Conv2D(filters=64, kernel_size=1, padding='same', kernel_initializer=hn)(concat_all)\n",
    "    #Segmentations from multiscale features *without softmax activation\n",
    "    seg_01 = Conv2D(4, (1,1), name='seg_01')(up01)\n",
    "    seg_02 = Conv2D(4, (1,1), name='seg_02')(up02)\n",
    "    seg_03 = Conv2D(4, (1,1), name='seg_03')(up02)\n",
    "\n",
    "    #----self guided attention blocks-----\n",
    "    ga_01 = guided_attention(up01, ms_feature, layer_name_ga[0])\n",
    "    ga_02 = guided_attention(up02, ms_feature, layer_name_ga[1])\n",
    "    ga_03 = guided_attention(up03, ms_feature, layer_name_ga[2])\n",
    "    #Segmentations from guided attention features *without softmax activation\n",
    "    seg_ga01 = Conv2D(4, (1,1), name='seg_ga01')(ga_01)\n",
    "    seg_ga02 = Conv2D(4, (1,1), name='seg_ga02')(ga_02)\n",
    "    seg_ga03 = Conv2D(4, (1,1), name='seg_ga03')(ga_03)\n",
    "    #outputs for xent losses\n",
    "    output_xent = [seg_01, seg_02, seg_03, seg_ga01, seg_ga02, seg_ga03]\n",
    "    #output for dice coefficient loss\n",
    "    pred_seg = Add()(output_xent)\n",
    "    output_dice = Softmax()(pred_seg/len(output_xent))\n",
    "    return output_xent, output_dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Build Model\n",
    "input_layer = Input(shape=(200,200,4))\n",
    "model = Model(input_layer, forward(input_layer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xent_logit = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "@tf.function\n",
    "def train_fn(image, label):\n",
    "    with tf.GradientTape() as tape:\n",
    "        output_xent, output_dice = model(image, training=True)\n",
    "        loss_dice = generalized_dice_loss(label, output_dice)\n",
    "        loss_xents=[]\n",
    "        for seg in output_xent:\n",
    "            loss_xent = xent_logit(label, seg)\n",
    "            loss_xents.append(loss_xent)\n",
    "        loss_total = sum(loss_xents)+loss_dice\n",
    "    gradients = tape.gradient(loss_total, model.trainable_variables)\n",
    "    opt.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    \n",
    "    return output_dice, loss_total, gradients\n",
    "\n",
    "@tf.function\n",
    "def val_fn(image, label):\n",
    "    model_output = model(image, training=False)\n",
    "    loss = custom_loss(label, model_output)\n",
    "    return model_output, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs = 1\n",
    "#list\n",
    "loss_list = []\n",
    "acc_list = []\n",
    "loss_inner = []\n",
    "while epochs <= max_epochs:\n",
    "    start = time.time()\n",
    "    print()\n",
    "    print(\"Epochs {:2d}\".format(epochs))\n",
    "    steps = 1\n",
    "    dc_app = []\n",
    "    sens_app = []\n",
    "    spec_app = []\n",
    "    ds = os.listdir(tfrecords_read_dir)\n",
    "    #shuffle directory list of tfrecords\n",
    "    shuffle = random.shuffle(ds)\n",
    "    for tf_re in ds:\n",
    "        tf_dir = os.path.join(tfrecords_read_dir+tf_re)\n",
    "        dataset = utils.parse_tfrecord(tf_dir).shuffle(SHUFFLE_BUFFER).batch(BATCH_SIZE)\n",
    "        acc_inner = []\n",
    "        for imgs in dataset:\n",
    "            #data augmentation\n",
    "            imgs = data_aug(imgs)\n",
    "            #crop images\n",
    "            image = imgs[:,20:220,20:220,:4]\n",
    "            #unprocessed label for plotting (cropped)\n",
    "            label = imgs[:,20:220,20:220,-1]\n",
    "            #for simplicity label 4 will be converted to 3 for sparse encoding\n",
    "            label = tf.where(label==4,3,label)\n",
    "            label = tf.keras.utils.to_categorical(label, num_classes=4)\n",
    "            img_seg, loss, gradients = train_fn(image, label) #training function\n",
    "            #map from sparse to label\n",
    "            img_seg = tf.math.argmax(img_seg,-1,output_type=tf.int32)\n",
    "            label = tf.math.argmax(label,-1,output_type=tf.int32)\n",
    "            #accuracy of the output values for that batch\n",
    "            acc = tf.reduce_mean(tf.cast(tf.equal(img_seg,label), tf.float32))\n",
    "            #append accuracy for every steps\n",
    "            acc_inner.append(acc)\n",
    "            if epochs%5==0:\n",
    "                model.save_weights('/home/kevinteng/Desktop/model_weights/model_{}.h5'.format(ver))\n",
    "                dc_list =compute_metric_dc(label,img_seg)\n",
    "                dc_app.append(dc_list)\n",
    "            #output\n",
    "            if steps%5000==0:\n",
    "                input_img = [image[0,:,:,0], plot_labels_color(label[0]), plot_labels_color(img_seg[0])]\n",
    "                caption = ['Input Image', 'Ground Truth', 'Model Output']\n",
    "                plot_comparison(input_img, caption, n_col = 3, figsize=(10,10))\n",
    "                loss_list.append(loss)\n",
    "                acc_stp = tf.reduce_mean(tf.cast(tf.equal(img_seg[0],label[0]), tf.float32))\n",
    "                dc_list_stp =compute_metric_dc(label[0],img_seg[0])\n",
    "                print(\"Steps: {}, Loss:{}\".format(steps, loss))\n",
    "                print(\"Accurary: {}\".format(acc_stp))\n",
    "                print(\"Seq: TC, ET, WT\")\n",
    "                print(\"Dice coefficient: {}\".format(dc_list_stp))\n",
    "                print(\"Gradient min:{}, max:{}\".format(np.min(gradients[0]), np.max(gradients[0])))\n",
    "            steps+=1\n",
    "        acc_list.append(np.mean(acc_inner))\n",
    "    if epochs%5==0:\n",
    "        mean_dc = np.mean(np.array(dc_app),0)\n",
    "        print()\n",
    "        print('-----------<Summary for Epoch:{}>------------'.format(epochs))\n",
    "        print(\"Mean Accuracy: {}\".format(np.mean(acc_list)))\n",
    "        #'core','enhancing','complete'\n",
    "        print(\"Seq: TC, ET, WT\")\n",
    "        print(\"Mean Dice coefficient: {}\".format(mean_dc))\n",
    "        print('------------------------------------------------')\n",
    "        print()\n",
    "    elapsed_time =(time.time()-start)/60 #unit in mins\n",
    "    print(\"Compute time per epochs: {:.2f} mins\".format(elapsed_time))\n",
    "    epochs+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('/home/kevinteng/Desktop/model_weights/model_{}.h5'.format(ver))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('/home/kevinteng/Desktop/model_weights/model_{}.h5'.format(ver))\n",
    "def output_fn(image):\n",
    "    w,h,c = image.shape\n",
    "    model.trainable = False\n",
    "    _, model_output = model(image)\n",
    "    # we need [240,240,155] to input into cloud validation\n",
    "    if w!=240:\n",
    "        #padding constant\n",
    "        p = int(240-w)\n",
    "        padding = tf.constant([[0,0],[p,p],[p,p],[0,0]]) #p=20\n",
    "        model_output = tf.pad(model_output, padding, \"CONSTANT\")\n",
    "    return model_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ds = '/home/kevinteng/Desktop/ssd02/BraTS2020_preprocessed05/'\n",
    "save_path = '/home/kevinteng/Desktop/ssd02/submission/'\n",
    "actual_label = '/home/kevinteng/Desktop/ssd02/MICCAI_BraTS2020_TrainingData/BraTS20_Training_001/BraTS20_Training_001_seg.nii.gz'\n",
    "#all brain affine are the same just pick one \n",
    "brain_affine = nib.load(actual_label).affine\n",
    "steps = 1\n",
    "acc_list = []\n",
    "for train_or_val in sorted(os.listdir(ds)):\n",
    "    save_dir = save_path + train_or_val+'_'+ver\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    merge01 = os.path.join(ds+train_or_val)\n",
    "    for patient in sorted(os.listdir(merge01)):\n",
    "        patient_id = patient.split('.')[0]\n",
    "        merge02 = os.path.join(merge01,patient)\n",
    "        imgs = np.load(merge02)\n",
    "        image = imgs[:,20:220,20:220,:4]\n",
    "        seg_output = 0 #flush RAM\n",
    "        seg_output = np.zeros((240,240,155))\n",
    "        for i in range(image.shape[0]):\n",
    "            inp = tf.expand_dims(image[i],0)\n",
    "            img_seg = output_fn(inp) #validation function \n",
    "            #map from sparse to label\n",
    "            seg_output[:,:,i] = np.argmax(img_seg,-1) \n",
    "        #convert label from 4 to 3 and np array and cast as int\n",
    "        seg_output= np.where(seg_output==3,4,seg_output).astype(np.uint8)\n",
    "        prediction_ni = nib.Nifti1Image(seg_output, brain_affine)\n",
    "        prediction_ni.to_filename(save_dir+'/{}.nii.gz'.format(patient_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            [(None, 200, 200, 4) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_2 (GaussianNoise (None, 200, 200, 4)  0           input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "coord_conv_2 (CoordConv)        (None, 200, 200, 64) 3520        gaussian_noise_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "group_normalization_8 (GroupNor (None, 200, 200, 64) 128         coord_conv_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_9 (PReLU)               (None, 200, 200, 64) 64          group_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv02 (SeparableConv2D)        (None, 200, 200, 128 8896        p_re_lu_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 200, 200, 128 0           conv02[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "group_normalization_9 (GroupNor (None, 200, 200, 128 256         dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_10 (PReLU)              (None, 200, 200, 128 128         group_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv03 (SeparableConv2D)        (None, 200, 200, 64) 9408        p_re_lu_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add01 (Add)                     (None, 200, 200, 64) 0           conv03[0][0]                     \n",
      "                                                                 coord_conv_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 200, 200, 64) 256         add01[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_3 (ReLU)                  (None, 200, 200, 64) 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "down_01 (SeparableConv2D)       (None, 100, 100, 128 8896        re_lu_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "group_normalization_10 (GroupNo (None, 100, 100, 128 256         down_01[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_11 (PReLU)              (None, 100, 100, 128 128         group_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv04 (SeparableConv2D)        (None, 100, 100, 256 34176       p_re_lu_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 100, 100, 256 0           conv04[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "group_normalization_11 (GroupNo (None, 100, 100, 256 512         dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_12 (PReLU)              (None, 100, 100, 256 256         group_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv05 (SeparableConv2D)        (None, 100, 100, 128 35200       p_re_lu_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add02 (Add)                     (None, 100, 100, 128 0           conv05[0][0]                     \n",
      "                                                                 down_01[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 100, 100, 128 512         add02[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_4 (ReLU)                  (None, 100, 100, 128 0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "down_02 (SeparableConv2D)       (None, 50, 50, 256)  34176       re_lu_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "group_normalization_12 (GroupNo (None, 50, 50, 256)  512         down_02[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_13 (PReLU)              (None, 50, 50, 256)  256         group_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv06 (SeparableConv2D)        (None, 50, 50, 512)  133888      p_re_lu_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 50, 50, 512)  0           conv06[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "group_normalization_13 (GroupNo (None, 50, 50, 512)  1024        dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_14 (PReLU)              (None, 50, 50, 512)  512         group_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv07 (SeparableConv2D)        (None, 50, 50, 256)  135936      p_re_lu_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add03 (Add)                     (None, 50, 50, 256)  0           conv07[0][0]                     \n",
      "                                                                 down_02[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 50, 50, 256)  1024        add03[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_5 (ReLU)                  (None, 50, 50, 256)  0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "down_03 (SeparableConv2D)       (None, 25, 25, 512)  133888      re_lu_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "group_normalization_14 (GroupNo (None, 25, 25, 512)  1024        down_03[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_15 (PReLU)              (None, 25, 25, 512)  512         group_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv08 (SeparableConv2D)        (None, 25, 25, 1024) 529920      p_re_lu_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 25, 25, 1024) 0           conv08[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "group_normalization_15 (GroupNo (None, 25, 25, 1024) 2048        dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_16 (PReLU)              (None, 25, 25, 1024) 1024        group_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv09 (SeparableConv2D)        (None, 25, 25, 512)  534016      p_re_lu_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add04 (Add)                     (None, 25, 25, 512)  0           conv09[0][0]                     \n",
      "                                                                 down_03[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_17 (PReLU)              (None, 25, 25, 512)  512         add04[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 50, 50, 128)  16512       add02[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 50, 50, 128)  32896       add03[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 25, 25, 256)  65792       add03[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 25, 25, 256)  131328      p_re_lu_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 100, 100, 64) 4160        add01[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 100, 100, 64) 8256        add02[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 50, 50, 128)  0           conv2d_12[0][0]                  \n",
      "                                                                 conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 25, 25, 256)  0           conv2d_14[0][0]                  \n",
      "                                                                 conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 100, 100, 64) 0           conv2d_10[0][0]                  \n",
      "                                                                 conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 50, 50, 128)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 25, 25, 256)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 100, 100, 64) 0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "grid_att02 (Conv2D)             (None, 50, 50, 1)    129         activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "gird_att03 (Conv2D)             (None, 25, 25, 1)    257         activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "grid_att01 (Conv2D)             (None, 100, 100, 1)  65          activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_6 (UpSampling2D)  (None, 100, 100, 1)  0           grid_att02[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_7 (UpSampling2D)  (None, 50, 50, 1)    0           gird_att03[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2D)  (None, 200, 200, 1)  0           grid_att01[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "multiply_4 (Multiply)           (None, 100, 100, 128 0           add02[0][0]                      \n",
      "                                                                 up_sampling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_5 (Multiply)           (None, 50, 50, 256)  0           add03[0][0]                      \n",
      "                                                                 up_sampling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_3 (Multiply)           (None, 200, 200, 64) 0           add01[0][0]                      \n",
      "                                                                 up_sampling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 100, 100, 64) 8256        multiply_4[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 50, 50, 64)   16448       multiply_5[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 200, 200, 64) 4160        multiply_3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_8 (UpSampling2D)  (None, 200, 200, 64) 0           conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_9 (UpSampling2D)  (None, 200, 200, 64) 0           conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 200, 200, 192 0           conv2d_16[0][0]                  \n",
      "                                                                 up_sampling2d_8[0][0]            \n",
      "                                                                 up_sampling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 200, 200, 64) 12352       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 200, 200, 128 0           conv2d_16[0][0]                  \n",
      "                                                                 conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 200, 200, 128 0           up_sampling2d_8[0][0]            \n",
      "                                                                 conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 200, 200, 128 0           up_sampling2d_9[0][0]            \n",
      "                                                                 conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 100, 100, 128 16512       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 100, 100, 128 16512       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 100, 100, 128 16512       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 100, 100, 128 16512       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 50, 50, 128)  16512       conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 100, 100, 128 16512       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 50, 50, 128)  16512       conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 100, 100, 128 16512       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 50, 50, 128)  16512       conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 50, 50, 128)  16512       conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_5 (TensorFl [(None, 2500, 128)]  0           conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 50, 50, 128)  16512       conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_13 (TensorF [(None, 2500, 128)]  0           conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 50, 50, 128)  16512       conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_21 (TensorF [(None, 2500, 128)]  0           conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "pam01_conv02block01 (Conv2D)    (None, 50, 50, 16)   2064        conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Einsum_3 (TensorFlo [(None, 128, 2500)]  0           tf_op_layer_Reshape_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_4 (TensorFl [(None, 2500, 128)]  0           conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "pam01_conv02block02 (Conv2D)    (None, 50, 50, 16)   2064        conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Einsum_9 (TensorFlo [(None, 128, 2500)]  0           tf_op_layer_Reshape_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_12 (TensorF [(None, 2500, 128)]  0           conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "pam01_conv02block03 (Conv2D)    (None, 50, 50, 16)   2064        conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Einsum_15 (TensorFl [(None, 128, 2500)]  0           tf_op_layer_Reshape_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_20 (TensorF [(None, 2500, 128)]  0           conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "pam01_conv01block01 (Conv2D)    (None, 50, 50, 16)   2064        conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 50, 50, 16)   0           pam01_conv02block01[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Einsum_4 (TensorFlo [(None, 128, 128)]   0           tf_op_layer_Einsum_3[0][0]       \n",
      "                                                                 tf_op_layer_Reshape_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "pam01_conv01block02 (Conv2D)    (None, 50, 50, 16)   2064        conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 50, 50, 16)   0           pam01_conv02block02[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Einsum_10 (TensorFl [(None, 128, 128)]   0           tf_op_layer_Einsum_9[0][0]       \n",
      "                                                                 tf_op_layer_Reshape_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "pam01_conv01block03 (Conv2D)    (None, 50, 50, 16)   2064        conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 50, 50, 16)   0           pam01_conv02block03[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Einsum_16 (TensorFl [(None, 128, 128)]   0           tf_op_layer_Einsum_15[0][0]      \n",
      "                                                                 tf_op_layer_Reshape_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 50, 50, 16)   0           pam01_conv01block01[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_1 (TensorFl [(None, 2500, 16)]   0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_6 (TensorFl [(None, 2500, 128)]  0           conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "cam01_softmaxblock01 (Softmax)  (None, 128, 128)     0           tf_op_layer_Einsum_4[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 50, 50, 16)   0           pam01_conv01block02[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_9 (TensorFl [(None, 2500, 16)]   0           activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_14 (TensorF [(None, 2500, 128)]  0           conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "cam01_softmaxblock02 (Softmax)  (None, 128, 128)     0           tf_op_layer_Einsum_10[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 50, 50, 16)   0           pam01_conv01block03[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_17 (TensorF [(None, 2500, 16)]   0           activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_22 (TensorF [(None, 2500, 128)]  0           conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "cam01_softmaxblock03 (Softmax)  (None, 128, 128)     0           tf_op_layer_Einsum_16[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape (TensorFlow [(None, 2500, 16)]   0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Einsum (TensorFlowO [(None, 16, 2500)]   0           tf_op_layer_Reshape_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "pam01_conv03block01 (Conv2D)    (None, 50, 50, 128)  16512       conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Einsum_5 (TensorFlo [(None, 2500, 128)]  0           tf_op_layer_Reshape_6[0][0]      \n",
      "                                                                 cam01_softmaxblock01[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_8 (TensorFl [(None, 2500, 16)]   0           activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Einsum_6 (TensorFlo [(None, 16, 2500)]   0           tf_op_layer_Reshape_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "pam01_conv03block02 (Conv2D)    (None, 50, 50, 128)  16512       conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Einsum_11 (TensorFl [(None, 2500, 128)]  0           tf_op_layer_Reshape_14[0][0]     \n",
      "                                                                 cam01_softmaxblock02[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_16 (TensorF [(None, 2500, 16)]   0           activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Einsum_12 (TensorFl [(None, 16, 2500)]   0           tf_op_layer_Reshape_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "pam01_conv03block03 (Conv2D)    (None, 50, 50, 128)  16512       conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Einsum_17 (TensorFl [(None, 2500, 128)]  0           tf_op_layer_Reshape_22[0][0]     \n",
      "                                                                 cam01_softmaxblock03[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Einsum_1 (TensorFlo [(None, 2500, 2500)] 0           tf_op_layer_Reshape[0][0]        \n",
      "                                                                 tf_op_layer_Einsum[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 50, 50, 128)  0           pam01_conv03block01[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_7 (TensorFl [(None, 50, 50, 128) 0           tf_op_layer_Einsum_5[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Einsum_7 (TensorFlo [(None, 2500, 2500)] 0           tf_op_layer_Reshape_8[0][0]      \n",
      "                                                                 tf_op_layer_Einsum_6[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 50, 50, 128)  0           pam01_conv03block02[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_15 (TensorF [(None, 50, 50, 128) 0           tf_op_layer_Einsum_11[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Einsum_13 (TensorFl [(None, 2500, 2500)] 0           tf_op_layer_Reshape_16[0][0]     \n",
      "                                                                 tf_op_layer_Einsum_12[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 50, 50, 128)  0           pam01_conv03block03[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_23 (TensorF [(None, 50, 50, 128) 0           tf_op_layer_Einsum_17[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "pam01_softmaxblock01 (Softmax)  (None, 2500, 2500)   0           tf_op_layer_Einsum_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_2 (TensorFl [(None, 2500, 128)]  0           activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 128)          0           tf_op_layer_Reshape_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "pam01_softmaxblock02 (Softmax)  (None, 2500, 2500)   0           tf_op_layer_Einsum_7[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_10 (TensorF [(None, 2500, 128)]  0           activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 128)          0           tf_op_layer_Reshape_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "pam01_softmaxblock03 (Softmax)  (None, 2500, 2500)   0           tf_op_layer_Einsum_13[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_18 (TensorF [(None, 2500, 128)]  0           activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_2 (Glo (None, 128)          0           tf_op_layer_Reshape_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Einsum_2 (TensorFlo [(None, 2500, 128)]  0           pam01_softmaxblock01[0][0]       \n",
      "                                                                 tf_op_layer_Reshape_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 16)           2064        global_average_pooling2d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Einsum_8 (TensorFlo [(None, 2500, 128)]  0           pam01_softmaxblock02[0][0]       \n",
      "                                                                 tf_op_layer_Reshape_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 16)           2064        global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Einsum_14 (TensorFl [(None, 2500, 128)]  0           pam01_softmaxblock03[0][0]       \n",
      "                                                                 tf_op_layer_Reshape_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 16)           2064        global_average_pooling2d_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_3 (TensorFl [(None, 50, 50, 128) 0           tf_op_layer_Einsum_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pam01_alphablock01 (Conv2D)     (None, 50, 50, 1)    129         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "cam01_alphablock01 (Dense)      (None, 128)          2176        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_11 (TensorF [(None, 50, 50, 128) 0           tf_op_layer_Einsum_8[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pam01_alphablock02 (Conv2D)     (None, 50, 50, 1)    129         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "cam01_alphablock02 (Dense)      (None, 128)          2176        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_19 (TensorF [(None, 50, 50, 128) 0           tf_op_layer_Einsum_14[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "pam01_alphablock03 (Conv2D)     (None, 50, 50, 1)    129         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "cam01_alphablock03 (Dense)      (None, 128)          2176        dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_6 (Multiply)           (None, 50, 50, 128)  0           tf_op_layer_Reshape_3[0][0]      \n",
      "                                                                 pam01_alphablock01[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "multiply_7 (Multiply)           (None, 50, 50, 128)  0           tf_op_layer_Reshape_7[0][0]      \n",
      "                                                                 cam01_alphablock01[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "multiply_9 (Multiply)           (None, 50, 50, 128)  0           tf_op_layer_Reshape_11[0][0]     \n",
      "                                                                 pam01_alphablock02[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "multiply_10 (Multiply)          (None, 50, 50, 128)  0           tf_op_layer_Reshape_15[0][0]     \n",
      "                                                                 cam01_alphablock02[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "multiply_12 (Multiply)          (None, 50, 50, 128)  0           tf_op_layer_Reshape_19[0][0]     \n",
      "                                                                 pam01_alphablock03[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "multiply_13 (Multiply)          (None, 50, 50, 128)  0           tf_op_layer_Reshape_23[0][0]     \n",
      "                                                                 cam01_alphablock03[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "pam01_addblock01 (Add)          (None, 50, 50, 128)  0           multiply_6[0][0]                 \n",
      "                                                                 conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "cam01_addblock01 (Add)          (None, 50, 50, 128)  0           multiply_7[0][0]                 \n",
      "                                                                 conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "pam01_addblock02 (Add)          (None, 50, 50, 128)  0           multiply_9[0][0]                 \n",
      "                                                                 conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "cam01_addblock02 (Add)          (None, 50, 50, 128)  0           multiply_10[0][0]                \n",
      "                                                                 conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "pam01_addblock03 (Add)          (None, 50, 50, 128)  0           multiply_12[0][0]                \n",
      "                                                                 conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "cam01_addblock03 (Add)          (None, 50, 50, 128)  0           multiply_13[0][0]                \n",
      "                                                                 conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 50, 50, 128)  0           pam01_addblock01[0][0]           \n",
      "                                                                 cam01_addblock01[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 50, 50, 128)  0           pam01_addblock02[0][0]           \n",
      "                                                                 cam01_addblock02[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 50, 50, 128)  0           pam01_addblock03[0][0]           \n",
      "                                                                 cam01_addblock03[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_10 (UpSampling2D) (None, 200, 200, 128 0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_11 (UpSampling2D) (None, 200, 200, 128 0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_12 (UpSampling2D) (None, 200, 200, 128 0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 200, 200, 64) 8256        up_sampling2d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 200, 200, 64) 8256        up_sampling2d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 200, 200, 64) 8256        up_sampling2d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "multiply_8 (Multiply)           (None, 200, 200, 64) 0           conv2d_24[0][0]                  \n",
      "                                                                 conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_11 (Multiply)          (None, 200, 200, 64) 0           conv2d_29[0][0]                  \n",
      "                                                                 conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_14 (Multiply)          (None, 200, 200, 64) 0           conv2d_34[0][0]                  \n",
      "                                                                 conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "seg_01 (Conv2D)                 (None, 200, 200, 4)  260         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "seg_02 (Conv2D)                 (None, 200, 200, 4)  260         up_sampling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "seg_03 (Conv2D)                 (None, 200, 200, 4)  260         up_sampling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "seg_ga01 (Conv2D)               (None, 200, 200, 4)  260         multiply_8[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "seg_ga02 (Conv2D)               (None, 200, 200, 4)  260         multiply_11[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "seg_ga03 (Conv2D)               (None, 200, 200, 4)  260         multiply_14[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 200, 200, 4)  0           seg_01[0][0]                     \n",
      "                                                                 seg_02[0][0]                     \n",
      "                                                                 seg_03[0][0]                     \n",
      "                                                                 seg_ga01[0][0]                   \n",
      "                                                                 seg_ga02[0][0]                   \n",
      "                                                                 seg_ga03[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_RealDiv (TensorFlow [(None, 200, 200, 4) 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "softmax (Softmax)               (None, 200, 200, 4)  0           tf_op_layer_RealDiv[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 2,212,974\n",
      "Trainable params: 2,212,078\n",
      "Non-trainable params: 896\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}