{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kevinteng/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/kevinteng/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/kevinteng/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/kevinteng/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/kevinteng/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/kevinteng/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/home/kevinteng/Desktop/BrainTumourSegmentation')\n",
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os \n",
    "import utils\n",
    "from utils_vis import plot_comparison, plot_labels_color \n",
    "from utils import dice_coef, ss_metric, compute_metric\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Blue => Label 1 (Necrotic and Non-enhancing Tumor Core)\n",
    "- Yellow => Label 2 (Peritumoral Edema)\n",
    "- Brown => Label 3/4 (GD-Enhancing Tumor)\n",
    "---\n",
    "* Core => Label 1 & 3\n",
    "* Enhancing => Label 3\n",
    "* Complete => Label 1,2, 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHUFFLE_BUFFER = 4000\n",
    "BATCH_SIZE = 8\n",
    "lr = 0.00001\n",
    "opt = tf.keras.optimizers.Adam(lr)\n",
    "ver = 'ResAttUnet_01' #save version \n",
    "dropout=0.2 #dropout rate\n",
    "hn = 'he_normal' #kernel initializer \n",
    "tfrecords_read_dir = '/home/kevinteng/Desktop/ssd02/BraTS20_tfrecords03/HGG/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "xent = tf.keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "def generalized_dice(y_true, y_pred, smooth = 1e-5):\n",
    "    \"\"\"\n",
    "    Generalized Dice Score\n",
    "    https://arxiv.org/pdf/1707.03237\n",
    "    https://github.com/Mehrdad-Noori/Brain-Tumor-Segmentation/blob/master/loss.py\n",
    "    \"\"\"\n",
    "    \n",
    "    y_true    = tf.reshape(y_true,shape=(-1,4))\n",
    "    y_pred    = tf.reshape(y_pred,shape=(-1,4))\n",
    "    sum_p     = tf.reduce_sum(y_pred, -2)\n",
    "    sum_r     = tf.reduce_sum(y_true, -2)\n",
    "    sum_pr    = tf.reduce_sum(y_true * y_pred, -2)\n",
    "    weights   = tf.math.pow(tf.math.square(sum_r) + smooth, -1)\n",
    "    generalized_dice = (2 * tf.reduce_sum(weights * sum_pr)) / (tf.reduce_sum(weights * (sum_r + sum_p)))\n",
    "    return generalized_dice\n",
    "\n",
    "def generalized_dice_loss(y_true, y_pred):   \n",
    "    return 1-generalized_dice(y_true, y_pred)\n",
    "    \n",
    "def custom_loss(y_true, y_pred):\n",
    "    \n",
    "    \"\"\"\n",
    "    The final loss function consists of the summation of two losses \"GDL\" and \"CE\"\n",
    "    with a regularization term.\n",
    "    \"\"\"\n",
    "    \n",
    "    return generalized_dice_loss(y_true, y_pred) + 1.25 * xent(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_model import conv_block, coordconv_block, up, pool, attention_block\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, UpSampling2D, Activation, Add, Multiply\n",
    "from tensorflow.keras.layers import BatchNormalization,PReLU\n",
    "\n",
    "def up_res(x_in, filters, merge, kernel_initializer='glorot_uniform', up_scale=(2, 2)):\n",
    "    u = UpSampling2D(up_scale)(x_in)\n",
    "    #convolution of 2x2 but linear activation\n",
    "    conv = Conv2D(filters, kernel_size=(2,2), \n",
    "                   padding='same', kernel_initializer=kernel_initializer)(u) \n",
    "    concat = tf.concat([merge, conv], axis=-1)\n",
    "    return concat\n",
    "\n",
    "def dual_conv(x, filters, batch_norm=True, kernel_initializer='glorot_uniform'):\n",
    "    if batch_norm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = PReLU(shared_axes = [1, 2])(x)\n",
    "    x = Conv2D(filters, 3, padding='same', kernel_initializer=kernel_initializer)(x)\n",
    "    if batch_norm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = PReLU(shared_axes = [1, 2])(x)\n",
    "    x = Conv2D(filters, 3, padding='same', kernel_initializer=kernel_initializer)(x)\n",
    "    return x\n",
    "\n",
    "def residual_block(x_in, filters, batch_norm=True, encoder_path = True, \n",
    "                kernel_initializer='glorot_uniform'):\n",
    "    #only for downsampling strides = 2\n",
    "    if encoder_path:\n",
    "        pre_skip = Conv2D(filters, kernel_size=(2,2), strides=(2, 2), \n",
    "                   padding='same', kernel_initializer=kernel_initializer)(x_in)\n",
    "    #entry block and upsampling block does not need stride 2\n",
    "    if not encoder_path: \n",
    "        pre_skip = Conv2D(filters, kernel_size=(2,2), \n",
    "           padding='same', kernel_initializer=kernel_initializer)(x_in)\n",
    "    #two layers of CNN\n",
    "    x = dual_conv(pre_skip, filters, batch_norm, kernel_initializer)\n",
    "    #addition for skip connection in res unit\n",
    "    if encoder_path:\n",
    "        x = Add()([x,pre_skip])\n",
    "    else:\n",
    "        x = Conv2D(filters, 1, use_bias=False)(x)\n",
    "        x = Add()([x,pre_skip])\n",
    "    return x\n",
    "\n",
    "def ResAttUnet_model(input_layer, attention_mode='grid'):\n",
    "    #entry block\n",
    "    #input shape [?,240,240,1], output shape  [?,240,240,1]\n",
    "    entry = Conv2D(64, kernel_size=(2,2), padding='same', \n",
    "                    kernel_initializer=hn)(input_layer)\n",
    "    res01 = dual_conv(entry, 64, kernel_initializer=hn)\n",
    "    res01 = Add()([res01, entry])\n",
    "    #downsampling path\n",
    "#     res01 = residual_block(input_layer, filters=64, kernel_initializer=hn)\n",
    "    #input shape [?,240,240,1], output shape  [?,120,120,1]\n",
    "    res02 = residual_block(res01, filters=128, kernel_initializer=hn)    \n",
    "    #input shape [?,120,120,1], output shape  [?,60,60,1]\n",
    "    res03 = residual_block(res02, filters=256, kernel_initializer=hn)\n",
    "    #bottle neck layer\n",
    "    #input shape [?,60,60,1], output shape  [?,30,30,1]\n",
    "    res04 = residual_block(res03, filters=512, kernel_initializer=hn)\n",
    "    \n",
    "    #upsampling path\n",
    "    #input shape [?,30,30,1], output shape  [?,60,60,1]\n",
    "    att01 = attention_block(res03, res04, 256)\n",
    "    up01 = up_res(res04,filters=256, merge=att01, kernel_initializer=hn)\n",
    "    res05 = residual_block(up01, filters=256, encoder_path = False, kernel_initializer=hn)\n",
    "    #input shape [?,60,60,1], output shape  [?,120,120,1]\n",
    "    if attention_mode=='grid':\n",
    "        att02 = attention_block(res02, res05, 128)\n",
    "    else:\n",
    "        att02 = attention_block(res02, res03, 128)\n",
    "    up02 = up_res(res05,filters=128, merge=att02, kernel_initializer=hn)\n",
    "    res06 = residual_block(up02, filters=128, encoder_path = False, kernel_initializer=hn)\n",
    "    #input shape [?,120,120,1], output shape  [?,240,240,1]\n",
    "    if attention_mode=='grid':\n",
    "        att03 = attention_block(res01, res06, 64)\n",
    "    else:\n",
    "        att03 = attention_block(res01, res02, 64)\n",
    "    up03 = up_res(res06,filters=64, merge=att03, kernel_initializer=hn)\n",
    "    res07 = residual_block(up03, filters=64, encoder_path = False, kernel_initializer=hn)\n",
    "    \n",
    "    output_layer = BatchNormalization()(res07)\n",
    "    output_layer = PReLU(shared_axes = [1, 2])(output_layer)\n",
    "    output_layer = Conv2D(4, (1,1), activation = 'softmax')(output_layer)\n",
    "    \n",
    "    return output_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "input_layer = Input(shape=(240,240,4))\n",
    "model = Model(input_layer, ResAttUnet_model(input_layer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to do..Sensitivity\n",
    "xent = tf.keras.losses.CategoricalCrossentropy()\n",
    "@tf.function\n",
    "def train_fn(image, label):\n",
    "    with tf.GradientTape() as tape:\n",
    "        model_output = model(image)\n",
    "        loss = custom_loss(label, model_output)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    opt.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    \n",
    "    return model_output, loss, gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epochs  1\n"
     ]
    }
   ],
   "source": [
    "epochs = 1\n",
    "max_epochs = 30\n",
    "#list\n",
    "loss_list = []\n",
    "acc_list = []\n",
    "loss_inner = []\n",
    "while epochs <= max_epochs:\n",
    "    print()\n",
    "    print(\"Epochs {:2d}\".format(epochs))\n",
    "    steps = 1\n",
    "    dc_app = []\n",
    "    sens_app = []\n",
    "    spec_app = []\n",
    "    for tf_re in sorted(os.listdir(tfrecords_read_dir)):\n",
    "        tf_dir = os.path.join(tfrecords_read_dir+tf_re)\n",
    "        dataset = utils.parse_tfrecord(tf_dir).shuffle(SHUFFLE_BUFFER).batch(BATCH_SIZE)\n",
    "        acc_inner = []\n",
    "        for imgs in dataset:\n",
    "            image = imgs[:,:,:,:4]\n",
    "            #unprocessed label for plotting \n",
    "            label = imgs[:,:,:,-1]\n",
    "            #for simplicity label 4 will be converted to 3 for sparse encoding\n",
    "            label = tf.where(label==4,3,label)\n",
    "            label = tf.keras.utils.to_categorical(label, num_classes=4)\n",
    "            img_seg, loss, gradients = train_fn(image, label) #training function \n",
    "            #map from sparse to label\n",
    "            img_seg = tf.math.argmax(img_seg,-1,output_type=tf.int32) \n",
    "            label = tf.math.argmax(label,-1,output_type=tf.int32)\n",
    "            #accuracy of the output values for that batch\n",
    "            acc = tf.reduce_mean(tf.cast(tf.equal(img_seg,label), tf.float32))\n",
    "            #append accuracy for every steps\n",
    "            acc_inner.append(acc)\n",
    "            if epochs%5==0:\n",
    "                dc_list, sens_list, spec_list =compute_metric(label,img_seg)\n",
    "                dc_app.append(dc_list)\n",
    "                sens_app.append(sens_list)\n",
    "                spec_app.append(spec_list)\n",
    "            #output\n",
    "            if steps%2000==0:\n",
    "                input_img = [image[0,:,:,0], plot_labels_color(label[0]), plot_labels_color(img_seg[0])]\n",
    "                caption = ['Input Image', 'Ground Truth', 'Model Output']\n",
    "                plot_comparison(input_img, caption, n_col = 3, figsize=(10,10))\n",
    "                loss_list.append(loss)\n",
    "                acc_stp = tf.reduce_mean(tf.cast(tf.equal(img_seg[0],label[0]), tf.float32))\n",
    "                dc_list_stp, sens_list_stp, spec_list_stp =compute_metric(label[0],img_seg[0])\n",
    "                print(\"Steps: {}, Loss:{}\".format(steps, loss))\n",
    "                print(\"Accurary: {}\".format(acc_stp))\n",
    "                print(\"Dice coefficient: {}\".format(dc_list_stp))\n",
    "                print(\"Sensitivity: {}\".format(sens_list_stp))\n",
    "                print(\"Specificity: {}\".format(spec_list_stp))\n",
    "                print(\"Gradient min:{}, max:{}\".format(np.min(gradients[0]), np.max(gradients[0])))\n",
    "            steps+=1\n",
    "        acc_list.append(np.mean(acc_inner))\n",
    "    if epochs%5==0:\n",
    "        mean_dc = np.mean(np.array(dc_app),0)\n",
    "        mean_sens = np.mean(np.array(sens_app),0)\n",
    "        mean_spec = np.mean(np.array(spec_app),0)\n",
    "        print()\n",
    "        print('-----------<Summary for Epoch:{}>------------'.format(epochs))\n",
    "        print(\"Mean Accuracy: {}\".format(np.mean(acc_list)))\n",
    "        print(\"Mean Dice coefficient: {}\".format(mean_dc))\n",
    "        print(\"Mean Sensitivity: {}\".format(mean_sens))\n",
    "        print(\"Mean Specificity: {}\".format(mean_spec))\n",
    "        print('------------------------------------------------')\n",
    "        print()\n",
    "    epochs+=1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('/home/kevinteng/Desktop/model_weights/model_{}.h5'.format(ver))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('/home/kevinteng/Desktop/model_weights/model_{}.h5'.format(ver))\n",
    "def val_fn(image, label):\n",
    "    model.trainable = False\n",
    "    model_output = model(image)\n",
    "    loss = xent(label, model_output)\n",
    "    return model_output, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tfrecords_val = '/home/kevinteng/Desktop/ssd02/BraTS20_tfrecords03/LGG/'\n",
    "\n",
    "steps = 1\n",
    "acc_list = []\n",
    "for tf_re in sorted(os.listdir(tfrecords_val)):\n",
    "    tf_dir = os.path.join(tfrecords_val+tf_re)\n",
    "    dataset = utils.parse_tfrecord(tf_dir).shuffle(SHUFFLE_BUFFER).batch(BATCH_SIZE)\n",
    "    dc_app = []\n",
    "    sens_app = []\n",
    "    spec_app = []\n",
    "    for imgs in dataset:\n",
    "        image = imgs[:,:,:,:4]\n",
    "        label = imgs[:,:,:,-1]\n",
    "        label = tf.where(label==4,3,label)\n",
    "        #for simplicity label 4 will be converted to 3 for sparse encoding\n",
    "        label = tf.keras.utils.to_categorical(label, num_classes=4)\n",
    "        img_seg, loss = val_fn(image, label) #validation function \n",
    "        #map from sparse to label\n",
    "        img_seg = tf.math.argmax(img_seg,-1,output_type=tf.int32) \n",
    "        label = tf.math.argmax(label,-1,output_type=tf.int32)\n",
    "        #accuracy of the output values for that batch\n",
    "        acc = tf.reduce_mean(tf.cast(tf.equal(img_seg,label), tf.float32))\n",
    "        dc_list, sens_list, spec_list =compute_metric(label,img_seg)\n",
    "        #append\n",
    "        acc_list.append(acc)\n",
    "        dc_app.append(dc_list)\n",
    "        sens_app.append(sens_list)\n",
    "        spec_app.append(spec_list)\n",
    "        #output\n",
    "        if steps%100==0:\n",
    "#             dc_list, sens_list, spec_list =compute_metric(label[0],img_seg[0])\n",
    "            input_img = [image[0,:,:,0], plot_labels_color(label[0]), plot_labels_color(img_seg[0])]\n",
    "            caption = ['Input Image', 'Ground Truth', 'Model Output']\n",
    "            plot_comparison(input_img, caption, n_col = 3, figsize=(10,10))\n",
    "            acc_stp = tf.reduce_mean(tf.cast(tf.equal(img_seg[0],label[0]), tf.float32))\n",
    "            dc_list, sens_list, spec_list =compute_metric(label[0],img_seg[0])\n",
    "            print(\"Steps: {}, Loss:{}\".format(steps, loss))\n",
    "            print(\"Accuracy: {}\".format(acc_stp))\n",
    "            print(\"Dice coefficient: {}\".format(dc_list))\n",
    "            print(\"Sensitivity: {}\".format(sens_list))\n",
    "            print(\"Specificity: {}\".format(spec_list))\n",
    "        steps+=1\n",
    "    mean_dc = np.mean(np.array(dc_app),0)\n",
    "    mean_sens = np.mean(np.array(sens_app),0)\n",
    "    mean_spec = np.mean(np.array(spec_app),0)\n",
    "    print(\"Mean Accuracy: {}\".format(np.mean(acc_list)))\n",
    "    print(\"Mean Dice coefficient: {}\".format(mean_dc))\n",
    "    print(\"Mean Sensitivity: {}\".format(mean_sens))\n",
    "    print(\"Mean Specificity: {}\".format(mean_spec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
